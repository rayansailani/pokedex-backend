{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe1b6ba-29dc-4865-b0f9-989aa07b77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43b5797-f5f3-4b3b-a549-d3bffcc27445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            images.append(img_array)\n",
    "            labels.append(folder)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5071c58-e14c-44c9-82f5-02d8633bcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'images'\n",
    "images, labels = load_images(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8b1f3f-4027-430e-b552-91576618ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to check if labels are correctly created\n",
    "# print(images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1de153-f995-4cb6-930b-40c1699c4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "labels_onehot = to_categorical(labels_encoded, num_classes=len(le.classes_))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0484b97-8a66-4066-9dc5-bdb0b12bed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to check if the sample is correctly created\n",
    "# print(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d365fd1b-9a27-411d-b1e4-9b3cb80fccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14b37a9-ec1c-4fb8-b700-6dbde7e00f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new layers for fine-tuning\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(le.classes_), activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f0a860a-832e-4aee-afed-8eb97b8ed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb481cec-8ba8-4606-bb7d-8a76bc66b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c916da-c237-4126-a439-7960ce4a0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b04fe8b-9177-4a7e-9c4a-91d48fcc9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('fine_tuned_model.keras', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1625302-7c9c-4be5-b08a-9f1e2311ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 11s/step - accuracy: 1.0000 - loss: 6.4615e-05 - val_accuracy: 0.3413 - val_loss: 7.3107\n",
      "Epoch 2/2\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 11s/step - accuracy: 1.0000 - loss: 5.1344e-05 - val_accuracy: 0.3453 - val_loss: 7.3672\n",
      "Epoch 1/2\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 11s/step - accuracy: 1.0000 - loss: 2.4888e-05 - val_accuracy: 0.3353 - val_loss: 8.6718\n",
      "Epoch 2/2\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 11s/step - accuracy: 1.0000 - loss: 8.2092e-06 - val_accuracy: 0.3373 - val_loss: 9.0180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x529a137c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=128, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "# Unfreeze some layers and fine-tune again\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=128, callbacks=[checkpoint, early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9221761-310c-4ac3-be21-9b2fcba91862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Assuming le is your LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)  # Replace `labels` with your actual labels variable\n",
    "\n",
    "# Save the label encoder\n",
    "joblib.dump(le, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb3fd16e-b7b5-428f-b189-9b0927769445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np \n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = load_model('fine_tuned_model.keras')\n",
    "\n",
    "# Load the label encoder and labels\n",
    "le = joblib.load('label_encoder.pkl')\n",
    "labels_encoded = np.load('pokemon_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f70239f1-04cb-4a74-af7a-46af5aa0337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print to check if labels are encoded or not.\n",
    "# labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035f8907-fdc6-4385-b821-a93ce7b8eb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I561728/Documents/Personal Development/pokedex-model/pokenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = load_model('fine_tuned_model.keras')\n",
    "\n",
    "# Load the label encoder and labels\n",
    "le = joblib.load('label_encoder.pkl')\n",
    "labels_encoded = np.load('pokemon_labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f974ce-d5eb-4af9-96e4-29a09f03a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of pokemon \n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def predict_pokemon(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_label = np.argmax(predictions, axis=1)[0]\n",
    "    pokemon_name = le.inverse_transform([predicted_label])[0]\n",
    "    return pokemon_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8aaa9b8-5bbf-4a61-a2f1-430ca75f5522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Predicted Pokémon: Tympole\n"
     ]
    }
   ],
   "source": [
    "# testing the model \n",
    "test_image_path = 'test/raichu.png'  # Replace with the path to a test image\n",
    "predicted_pokemon = predict_pokemon(test_image_path)\n",
    "\n",
    "print(f'Predicted Pokémon: {predicted_pokemon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193065d-ec50-41d8-b78a-fa1aaff4c341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
